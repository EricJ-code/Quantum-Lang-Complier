{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexical Analysis Tool for Schrodinger's Language: A Python Implementation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the realm of programming languages, especially those as niche and sophisticated as Schrodinger's Language - a language built around the concepts of quantum computing - understanding and categorizing the basic elements of the language becomes paramount. This report delves into a Python script designed to perform lexical analysis on Schrodinger's Language, effectively categorizing its syntax into literals, operators, variables, reserved words, and data types. This tool not only aids in the comprehension of Schrodinger's Language but also serves as a foundational step towards its compilation and execution.\n",
    "\n",
    "## Tool Overview\n",
    "\n",
    "The lexical analysis tool is a Python script that reads a snippet or file of Schrodinger's Language code and systematically categorizes its syntactic elements into five distinct categories:\n",
    "\n",
    "- **Literals**: Numeric values and string literals that represent fixed values.\n",
    "- **Operators**: Symbols that denote operations, particularly focusing on quantum gates.\n",
    "- **Variables**: Identifiers used to represent quantum states or other data.\n",
    "- **Reserved Words**: Keywords that have special meaning in Schrodinger's Language.\n",
    "- **Data Types**: The types of data represented in the language, with a primary focus on quantum bits (qubits).\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "### Pattern Definition\n",
    "\n",
    "The script utilizes regular expressions to identify different syntactic elements. Each category (literals, operators, variables, reserved words, data types) is associated with a specific pattern. For instance, quantum gates like Hadamard (H) and Controlled NOT (CNOT) are recognized as operators, while identifiers following the pattern `qubit_state_[number]` are categorized as variables.\n",
    "\n",
    "### Tokenization Process\n",
    "\n",
    "The core function, `tokenize(code)`, processes the input code to match against predefined patterns. It uses the Python `re` module to find matches for each category within the code. This process segregates the code into tokens that are then categorized accordingly.\n",
    "\n",
    "### Reporting\n",
    "\n",
    "Once the code is tokenized, the `print_report(tokens)` function generates a detailed report. It lists the count and the distinct instances of each category found in the input code. Additionally, the report includes the total number of lines processed, offering insight into the code's size.\n",
    "\n",
    "## Usage\n",
    "\n",
    "To utilize this tool, users should replace the placeholder code within the `if __name__ == \"__main__\":` block with the target Schrodinger's Language code or implement a mechanism to read from a file. Upon execution, the script will display a categorized report of the syntactic elements present in the code.\n",
    "\n",
    "## Customization and Extensibility\n",
    "\n",
    "The tool is designed with flexibility in mind, allowing for easy adjustments to the patterns to match specific syntax rules of Schrodinger's Language or extensions to handle additional syntactic categories. Users can modify regular expressions in the `PATTERNS` dictionary to refine the tool's accuracy or to adapt it to different dialects or languages within the quantum computing domain.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This lexical analysis tool stands as a testament to the power of scripting and pattern matching in understanding and dissecting programming languages. By providing a clear categorization of Schrodinger's Language syntax, it paves the way for further development, analysis, and ultimately, the effective use of this quantum computing language. Whether for educational purposes, language development, or code analysis, this Python script offers a foundational tool that enhances our interaction with the complex and promising field of quantum computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define patterns for different categories\n",
    "PATTERNS = {\n",
    "    'literals': r'\\b\\d+\\.?\\d*|\\'.*?\\'\\b',  # Numbers and strings\n",
    "    'operators': r'\\b(H|X|Y|Z|CNOT|np\\.dot)\\b',  # Quantum gates and np.dot\n",
    "    'variables': r'\\bqubit_state_[0-9]+\\b',  # Variables like qubit_state_0, qubit_state_1, etc.\n",
    "    'reserved_words': r'\\b(qubit|quantum-circuit|apply|measure)\\b',  # Keywords in the language\n",
    "    'data_types': r'\\bQubits\\b'  # Simplified to 'Qubits' for this context\n",
    "}\n",
    "\n",
    "def tokenize(code):\n",
    "    \"\"\"\n",
    "    Tokenize the input code into categories based on PATTERNS.\n",
    "    \"\"\"\n",
    "    tokens = {category: [] for category in PATTERNS}\n",
    "\n",
    "    for category, pattern in PATTERNS.items():\n",
    "        matches = re.findall(pattern, code)\n",
    "        tokens[category].extend(matches)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def print_report(tokens):\n",
    "    \"\"\"\n",
    "    Print a report based on the categorized tokens.\n",
    "    \"\"\"\n",
    "    print(\"Parsing Report:\")\n",
    "    print(\"=\"*40)\n",
    "    for category, items in tokens.items():\n",
    "        unique_items = set(items)  # Remove duplicates for listing\n",
    "        print(f\"{category.capitalize()} (count: {len(items)}): {', '.join(unique_items) if items else 'None'}\")\n",
    "    \n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total lines processed: {len(code.splitlines())}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample code (you can replace this with file reading logic)\n",
    "    code = \"\"\"\n",
    "    qubit q1\n",
    "    qubit q2\n",
    "    H(q1)\n",
    "    CNOT(q1, q2)\n",
    "    measure(q1)\n",
    "    measure(q2)\n",
    "    np.dot(H, qubit_state_0)\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = tokenize(code)\n",
    "    print_report(tokens)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
